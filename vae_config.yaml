apache_params:
  blade_chord_m: .533
  rotor_diameter_m: 14.63
  wheel_height_m: .76196
  phase_center_offset_m: .4953
  rotor_velocity_rad_s: 29.7404
  rotor_pitch_max: -10
  rotor_pitch_min: 30
  dismount_slant_range_min: 500
  dismount_slant_range_max: 15000
  vehicle_slant_range_min: 500
  vehicle_slant_range_max: 25000
  alt_min: 30.48
  alt_max: 1524.
  az_min_bw: .866
  el_min_bw: 8.

settings:
  cpi_len: 32
  batch_sz: 128
  fc: 10000000000.
  bandwidth: 400000000.
  stft_win_sz: 256
  plp: .5
  n_ants: 2
  fft_len: 8192

generate_data_settings:
  iterations: 500
  run_clutter: True
  run_targets: False
  use_local_storage: True
  local_path: ./data

# This is for setting up training of autoencoder
exp_params:
  LR: 0.001
  weight_decay: 0.01
  scheduler_gamma: 0.1
  betas: [.07, .9]
  step_size: 2
  swa_start: .5
  log_epoch: 10
  save_model: True
  transform_data: True
  warm_start: True
  loss_landscape: False
  output_images: False
  model_type: Encoder
  patience: 150
  is_tuning: False
  max_epochs: 50
  exp_name: train-latent512tanh
  dataset_params:
    data_path: ./data
    train_batch_size: 256
    val_batch_size: 256
    num_workers: 0
    pin_memory: False
    split: .7
    single_example: False
    # These values are taken from a sampling of data
    mu: 274662906.04691434
    var: 49527137064.739006
    noise_level: 0.

# For training of wavemodel
wave_exp_params:
  LR: 0.000001
  weight_decay: 0.01
  scheduler_gamma: 0.8
  swa_start: .6
  warm_start: False
  betas: [.9, .99]
  step_size: 3
  log_epoch: 10
  is_tuning: False
  save_model: True
  loss_landscape: False
  patience: 350
  channel_sz: 64
  bandwidth: 400000000.
  max_epochs: 1
  init_task: False
  exp_name: wavemodel-12x12-channel64
  dataset_params:
    data_path: ./data
    train_batch_size: 64
    val_batch_size: 64
    num_workers: 0
    pin_memory: False
    split: .7
    single_example: False
    # These values are taken from a sampling of data
    mu: 274662906.04691434
    var: 49527137064.739006
    noise_level: 0.

# For training of rcs model
rcs_exp_params:
  LR: 0.000000001
  weight_decay: 0.08
  scheduler_gamma: 0.95
  kld_weight: .39
  log_epoch: 10
  is_tuning: False
  save_model: False
  loss_landscape: False
  output_images: True
  patience: 15

# This refers to the autoencoder compression params
model_params:
  in_channels: 2
  latent_dim: 512
  max_capacity: 25
  channel_sz: 2
  capacity_max_iter: 10000
  reg_weight: 7840.  # MMD weight
  kernel_type: 'rbf'
  activation: leaky

train_params:
  log_dir: ./logs
